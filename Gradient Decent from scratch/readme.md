# Gradient Descent from Scratch in Python

This repository contains an implementation of the Gradient Descent optimization algorithm built from scratch using Python. The project is designed to provide a clear understanding of how the Gradient Descent algorithm works at a fundamental level, making it a valuable resource for anyone interested in learning about optimization in machine learning.

---

## ðŸ“‚ Project Structure

- `gradient_decent_from_scratch.py`: The Python script implementing the Gradient Descent algorithm.
- `README.md`: This file, explaining the project and how to use it.

---

## ðŸ›  Features

- Implements **Batch Gradient Descent**.
- Customizable parameters:
  - Learning rate (`learning_rate`)
  - Number of iterations (`epochs`)
  - Initial parameter values (`m (for slope), b (for intercept)`)
- Includes a demonstration of minimizing a simple cost function (e.g., Mean Squared Error).
- Supports visualizations of the cost function over iterations.

---

## ðŸš€ Getting Started

### Prerequisites
Make sure you have the following installed:
- Python 3.x
- Required libraries: `numpy`, `matplotlib`

Install the libraries using:
```bash
pip install numpy matplotlib
```
## Usage
1. Clone the repository: git clone https://github.com/teamarnab/ML-algorithms-built-from-scratch/tree/main/Gradient%20Decent%20from%20scratch
2. Navigate to the project folder: cd gradient-descent-from-scratch
3. Run the Python script: python gradient_decent_from_scratch.py